{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "f2ag76tw8zri"
      },
      "source": [
        "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-датасета\" data-toc-modified-id=\"Загрузка-датасета-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка датасета</a></span></li><li><span><a href=\"#Предобработка-текста\" data-toc-modified-id=\"Предобработка-текста-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Предобработка текста</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выполним-лемматизацию-текста\" data-toc-modified-id=\"Выполним-лемматизацию-текста-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Выполним лемматизацию текста</a></span></li><li><span><a href=\"#Создание-мешка-слов-и-TF-IDF\" data-toc-modified-id=\"Создание-мешка-слов-и-TF-IDF-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Создание мешка слов и TF IDF</a></span></li></ul></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Catboost\" data-toc-modified-id=\"Catboost-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Catboost</a></span></li><li><span><a href=\"#Тестирование-лучшей-модели-на-тестовой-выборке\" data-toc-modified-id=\"Тестирование-лучшей-модели-на-тестовой-выборке-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Тестирование лучшей модели на тестовой выборке</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrfADWu_8zrj"
      },
      "source": [
        "# Проект для «Викишоп»"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBxEHl9e8zrj"
      },
      "source": [
        "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
        "\n",
        "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Постройте модель со значением метрики качества *F1* не меньше 0.75.\n",
        "\n",
        "**Инструкция по выполнению проекта**\n",
        "\n",
        "1. Загрузите и подготовьте данные.\n",
        "2. Обучите разные модели.\n",
        "3. Сделайте выводы.\n",
        "\n",
        "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
        "\n",
        "**Описание данных**\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU9yWdie8zrj"
      },
      "source": [
        "## Подготовка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXwDWYZa8zrj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import *\n",
        "\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vS5orXh8zrk"
      },
      "source": [
        "### Загрузка датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9zdwMCz8zrk"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/datasets/toxic_comments.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "YpWVimtY8zrk",
        "outputId": "59c73b3c-2ae1-4819-b760-b5debc306644"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text  toxic\n",
              "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1           1  D'aww! He matches this background colour I'm s...      0\n",
              "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4           4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nmOsTWv8zrk"
      },
      "outputs": [],
      "source": [
        "df.drop(columns='Unnamed: 0', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "XcTfZETl8zrk",
        "outputId": "af1d6dba-8dc5-4892-d380-69c85d2b6392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159292 entries, 0 to 159291\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    159292 non-null  object\n",
            " 1   toxic   159292 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 2.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXBouuHO8zrl"
      },
      "source": [
        "### Предобработка текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAviP-HH8zrl"
      },
      "source": [
        "#### Выполним лемматизацию текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTd0fl1T8zrl"
      },
      "source": [
        "Напишем вспомогательную функцию для лемматизации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_6pbADA8zrl"
      },
      "outputs": [],
      "source": [
        "# Lemmatize with POS Tag\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper() # 0 строка, 1 - первый (после 0) элемент, 0 - нулевая буква\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "#это безопасный способ получения значения по ключу (method get() )\n",
        "#(если не найдено запрашиваемого ключа, то вернет, что слово существительное)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP5LdzNl8zrl"
      },
      "outputs": [],
      "source": [
        "def lemm(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    word_list = nltk.word_tokenize(text)\n",
        "    result = []\n",
        "    for s in word_list:\n",
        "        if s == \"n't\":\n",
        "            s = 'not'\n",
        "            result.append(lemmatizer.lemmatize(s, get_wordnet_pos(s)))\n",
        "        elif s == \"'m\":\n",
        "            s = \"am\"\n",
        "            result.append(lemmatizer.lemmatize(s,  get_wordnet_pos(s)))\n",
        "        else:\n",
        "            result.append(lemmatizer.lemmatize(s,  get_wordnet_pos(s)))\n",
        "    return \" \".join(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XejfVc0r8zrl"
      },
      "source": [
        "Напишем доп функцию очистки текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BavEacbw8zrl"
      },
      "outputs": [],
      "source": [
        "def clear_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z]', \" \", text.lower()) #lower\n",
        "    text_list = text.split()\n",
        "    return \" \".join(text_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQsn_RmW8zrl",
        "outputId": "7b16df99-643c-4a34-e288-2a078be4799b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWsr0Mmy8zrl",
        "outputId": "6359c1f6-8dbe-4ec7-b64d-b445b404f73c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 159292/159292 [38:38<00:00, 68.71it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(len(df))):\n",
        "    df.loc[i, 'lemm_text'] = lemm(clear_text(df.loc[i, 'text']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frEQHwiP8zrl"
      },
      "source": [
        "#### Создание мешка слов и TF IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aWhtq908zrl"
      },
      "source": [
        "Перед создание мешка слов необходимо разделить выборку на обучающую и тестовую. Как правило, мы делим в отношении 80:20, но в данной задаче целесообразно отдать на обучение больший датасет, пожтому разделим в отношении 90:10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "2GqNe5MU8zrl",
        "outputId": "b1c95bc9-6a99-44fe-fd30-3d13d758816d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>lemm_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>explanation why the edits make under my userna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>d aww he match this background colour i m seem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>hey man i m really not try to edit war it s ju...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>more i can t make any real suggestion on impro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>you sir be my hero any chance you remember wha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic  \\\n",
              "0  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  D'aww! He matches this background colour I'm s...      0   \n",
              "2  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "                                           lemm_text  \n",
              "0  explanation why the edits make under my userna...  \n",
              "1  d aww he match this background colour i m seem...  \n",
              "2  hey man i m really not try to edit war it s ju...  \n",
              "3  more i can t make any real suggestion on impro...  \n",
              "4  you sir be my hero any chance you remember wha...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7kEtx_w8zrm"
      },
      "outputs": [],
      "source": [
        "# Разделение на признаки (X) и целевую переменную (y)\n",
        "X = df['lemm_text']\n",
        "y = df['toxic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOzPYVJy8zrm",
        "outputId": "103ee86f-fea7-4335-aeb4-6387d5571dc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_size / test_size = 8.999497802887634\n",
            "balance of class in df = 0.10\n",
            "balance of class in train = 0.10\n",
            "balance of class in test = 0.10\n"
          ]
        }
      ],
      "source": [
        "#Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=df['toxic'])\n",
        "print(f'train_size / test_size = {X_train.shape[0] / X_test.shape[0]}')\n",
        "print(f'balance of class in df = {df[\"toxic\"].mean():.2f}')\n",
        "print(f'balance of class in train = {y_train.mean():.2f}')\n",
        "print(f'balance of class in test = {y_test.mean():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLpr_Hx58zrm"
      },
      "source": [
        "Деление на выборки выполнено корректо и также сохранен баланс классов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl5TWagT8zrm",
        "outputId": "ed38bf27-5d3d-4a7f-bc2a-73a714f11665"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words_list = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtmCA2538zrm"
      },
      "outputs": [],
      "source": [
        "corpus_train = X_train.values\n",
        "corpus_test = X_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l31uDbbq8zrm",
        "outputId": "ec78e3d0-9e6d-4a3e-d7f1-5629d8636293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 6.61 s, sys: 111 ms, total: 6.72 s\n",
            "Wall time: 6.73 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "#object of bow\n",
        "count_vect = CountVectorizer(stop_words=list(stop_words_list))\n",
        "\n",
        "#fit at the train data\n",
        "train_vectorized = count_vect.fit(corpus_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F5J97J28zrm",
        "outputId": "fe65082c-618f-4f02-81fd-094e5ddd5d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train bow shape (143362, 142266)\n",
            "test bow shape (15930, 142266)\n",
            "CPU times: user 7.37 s, sys: 39.6 ms, total: 7.41 s\n",
            "Wall time: 7.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "#transform train and test\n",
        "train_vectorized = count_vect.transform(corpus_train)\n",
        "test_vectorized = count_vect.transform(corpus_test)\n",
        "\n",
        "print(f'train bow shape {train_vectorized.shape}')\n",
        "print(f'test bow shape {test_vectorized.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAbUkgvm8zrn",
        "outputId": "5fcdb80b-1f38-40e2-b178-f0ecf2d540a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 6.7 s, sys: 76 ms, total: 6.78 s\n",
            "Wall time: 6.78 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "#object of TF_IDF\n",
        "count_tf_idf = TfidfVectorizer(stop_words=list(stop_words_list))\n",
        "\n",
        "#fit at the train data\n",
        "train_tf_idf = count_tf_idf.fit(corpus_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ohi-D_g78zrn",
        "outputId": "b1f10225-f0cf-46d9-fc54-073f718435e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train TF IDF shape (143362, 142266)\n",
            "test TF IDF shape (15930, 142266)\n",
            "CPU times: user 7.33 s, sys: 16.8 ms, total: 7.35 s\n",
            "Wall time: 7.37 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "#transfotm train and test\n",
        "train_tf_idf = count_tf_idf.transform(corpus_train)\n",
        "test_tf_idf = count_tf_idf.transform(corpus_test)\n",
        "\n",
        "print(f'train TF IDF shape {train_tf_idf.shape}')\n",
        "print(f'test TF IDF shape {test_tf_idf.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnRgR0MN8zrn"
      },
      "source": [
        "Вывод:\n",
        "\n",
        "- проведена лемматизация текста, результаты сохранены в столбец 'lemm_text'\n",
        "- с помощью метода мешок слов выполнен перевод текста в векторный формат\n",
        "- сформированы TF IDF для обучающей и тестовой выборок"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeUTkL8J8zrn"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLnR_pFA8zrn"
      },
      "source": [
        "### Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrgqJ3c98zrn",
        "outputId": "c3666285-cb56-4323-dd12-ec9b4b4bf729"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 31.5 s, sys: 65.2 ms, total: 31.5 s\n",
            "Wall time: 31.6 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, error_score='raise',\n",
              "             estimator=LogisticRegression(class_weight='balanced',\n",
              "                                          random_state=42, solver='saga'),\n",
              "             n_jobs=-1, param_grid={'l1_ratio': [0], 'penalty': ['elasticnet']},\n",
              "             scoring='f1')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "model = LogisticRegression(random_state = 42,\n",
        "                           solver='saga',\n",
        "                           max_iter=100,\n",
        "                           class_weight='balanced')\n",
        "parameters = {\n",
        "    'penalty' : ['elasticnet'],\n",
        "    'l1_ratio' : [0] # 0 - is equal L2, 1 - L1\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator = model,\n",
        "    param_grid = parameters,\n",
        "    scoring = 'f1',\n",
        "    n_jobs = -1,\n",
        "    cv = 2,\n",
        "    error_score = 'raise',\n",
        ")\n",
        "\n",
        "grid.fit(train_tf_idf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTDWknVm8zrn",
        "outputId": "3c90a8e0-cb7a-4a11-bda7-319a24e98265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best_model: LogisticRegression(class_weight='balanced', l1_ratio=0, penalty='elasticnet',\n",
            "                   random_state=42, solver='saga')\n",
            "Best_parametrs: {'l1_ratio': 0, 'penalty': 'elasticnet'}\n",
            "Best F1 score: 0.7422184177100739\n"
          ]
        }
      ],
      "source": [
        "print(f'Best_model: {grid.best_estimator_}')\n",
        "print(f'Best_parametrs: {grid.best_params_}')\n",
        "print(f'Best F1 score: {(grid.best_score_)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0KEuhRz8zro"
      },
      "source": [
        "### Catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTSIYp5P8zro"
      },
      "source": [
        "Catboost способен \"под капотом\" обрабатывать естественный текст. Поэтому передадим ему в качестве аргументов лемматизированный текст"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuW2LGze8zro",
        "outputId": "601671be-0976-46d5-f6bd-4f2522cddf33"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemm_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22585</th>\n",
              "      <td>please stop if you continue to vandalize page ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150346</th>\n",
              "      <td>your chanology nonviolence comment you say tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16991</th>\n",
              "      <td>all the change in which the specie abbreviatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51659</th>\n",
              "      <td>red head boy blonde girl tease tease brunette ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51916</th>\n",
              "      <td>britain in need help stop islam in britain vot...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                lemm_text\n",
              "22585   please stop if you continue to vandalize page ...\n",
              "150346  your chanology nonviolence comment you say tha...\n",
              "16991   all the change in which the specie abbreviatio...\n",
              "51659   red head boy blonde girl tease tease brunette ...\n",
              "51916   britain in need help stop islam in britain vot..."
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#передем обратно в формат dataframe\n",
        "X_train_cat = pd.DataFrame(X_train.astype('str'))\n",
        "X_train_cat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTeI66g_8zro",
        "outputId": "68f78055-7dfe-422b-8c03-cad85f2b9d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 20min 13s, sys: 1min 8s, total: 21min 21s\n",
            "Wall time: 21min 38s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2,\n",
              "             estimator=<catboost.core.CatBoostClassifier object at 0x7f711bec49a0>,\n",
              "             param_grid={'learning_rate': [0.5], 'logging_level': ['Silent'],\n",
              "                         'max_depth': [3, 5], 'random_seed': [42]},\n",
              "             scoring='f1')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "model = CatBoostClassifier()\n",
        "params = {\n",
        "    'max_depth' : [3, 5],\n",
        "    'random_seed' : [42],\n",
        "    'learning_rate' : [0.5],\n",
        "    'logging_level' : ['Silent'],\n",
        "}\n",
        "grid = GridSearchCV(estimator = model,\n",
        "                    param_grid = params,\n",
        "                    cv = 2,\n",
        "                    scoring = 'f1')\n",
        "\n",
        "grid.fit(X_train_cat, y_train,\n",
        "         text_features = ['lemm_text'],\n",
        "         plot = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "F6PEslky8zro",
        "outputId": "71f961e3-4243-4208-c50e-5761f8b22c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best_model: <catboost.core.CatBoostClassifier object at 0x7f711bec4130>\n",
            "Best_parametrs: {'learning_rate': 0.5, 'logging_level': 'Silent', 'max_depth': 5, 'random_seed': 42}\n",
            "Best F1 score: 0.7762087998107858\n"
          ]
        }
      ],
      "source": [
        "print(f'Best_model: {grid.best_estimator_}')\n",
        "print(f'Best_parametrs: {grid.best_params_}')\n",
        "print(f'Best F1 score: {(grid.best_score_)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGRzPc5f8zro"
      },
      "source": [
        "Catboost дал результаты чуть лучше, чем Логистическая регрессия (0.77 против 0.74). Поэтому в качестве финальной модели обучим CatBoost с лучшими подобранными параметрами"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPuuBJR98zro"
      },
      "source": [
        "### Тестирование лучшей модели на тестовой выборке"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjvguMh58zro",
        "outputId": "d41df8bd-79cf-43ab-fa52-2957f650539b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 6min 44s, sys: 23 s, total: 7min 7s\n",
            "Wall time: 7min 12s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f711e5e4910>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "best_model = CatBoostClassifier(max_depth = 5,\n",
        "                           random_seed = 42,\n",
        "                           learning_rate = 0.5,\n",
        "                           logging_level = 'Silent',\n",
        "                           eval_metric = 'F1')\n",
        "\n",
        "\n",
        "best_model.fit(X_train_cat,\n",
        "          y_train,\n",
        "          text_features = ['lemm_text'],\n",
        "          plot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCQ2Rr1g8zro"
      },
      "source": [
        "Чтобы проверить предсказания модели на тесте и посчитать тестовую метрику f1-score выполним подготовку признаков features_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6P0pcbS8zro"
      },
      "outputs": [],
      "source": [
        "#передем обратно в формат dataframe\n",
        "X_test_cat = pd.DataFrame(X_test.astype('str'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So6EXyPz8zro",
        "outputId": "ed41eb4e-17d6-47bc-9664-e428f9af016a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2.16 s, sys: 8.71 ms, total: 2.17 s\n",
            "Wall time: 2.21 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "predictions_test = best_model.predict(X_test_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyBtXnRT8zro",
        "outputId": "fa8e58f7-8dd6-44a0-98f5-b9cc1beaf8fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 score for test: 0.798542080848244\n"
          ]
        }
      ],
      "source": [
        "f1 = f1_score(y_test, predictions_test)\n",
        "print('F1 score for test:', f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4daT0DX8zro"
      },
      "source": [
        "## Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwEFxQ2x8zro"
      },
      "source": [
        "В процессе работы было сделано:\n",
        "- проведена лемматизация текста с помощью WordNetLemmatizer (NLTK), результаты сохранены в столбец 'lemm_text'\n",
        "- проведено деление исходной выборки в отношении 90:10 (обуч и тест)\n",
        "- с помощью метода мешок слов выполнен перевод текста в векторный формат\n",
        "- сформированы TF IDF для обучающей и тестовой выборок\n",
        "\n",
        "В качестве моделей машинного обучения были выбраны:\n",
        "- Логистическа регрессиия (обучение на TF IDF)\n",
        "- Модель градиентного бустинга CatBoost (обучалась на лемматищированном тексте)\n",
        "\n",
        "По результатам при кросс-валидации чуть лучше оказалась модель CatBoost (метрика F1 0.77 против 0.74)\n",
        "\n",
        "На тестовой выборке итоговая модель CatBoost показала результат F1 = 0.799, что выше требуемых в задании 0.75, поэтому цель задания достигнута."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sDBskn-8zrp"
      },
      "source": [
        "<font color='green'><b>Полезные (и просто интересные) материалы:</b> \\\n",
        "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
        "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
        "https://huggingface.co/transformers/model_doc/bert.html \\\n",
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
        "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
        "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
        "по трансформеру от создателей pytorch\\\n",
        "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
        "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
        "методов для трансформеров методов NLP \\\n",
        "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html\n",
        "\n",
        "<font color='green'>Пример BERT с GPU:\n",
        "```python\n",
        "%%time\n",
        "from tqdm import notebook\n",
        "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
        "embeddings = []\n",
        "model.cuda()   # закидываем модель на GPU\n",
        "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
        "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
        "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
        "\n",
        "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
        "        del batch\n",
        "        del attention_mask_batch\n",
        "        del batch_embeddings\n",
        "\n",
        "features = np.concatenate(embeddings)\n",
        "```\n",
        "Можно сделать предварительную проверку на наличие GPU.\\\n",
        "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
        "Тогда вместо .cuda() нужно писать .to(device)\n",
        "\n",
        "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
        "\n",
        "\n",
        "NLP от Samsung https://stepik.org/course/54098/promo \\\n",
        "NLP от Huawei https://ods.ai/tracks/nlp-course-spring-23\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtOzKWWX8zrp"
      },
      "source": [
        "## Чек-лист проверки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zACkD5CT8zrp"
      },
      "source": [
        "- [x]  Jupyter Notebook открыт\n",
        "- [x]  Весь код выполняется без ошибок\n",
        "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
        "- [x]  Данные загружены и подготовлены\n",
        "- [x]  Модели обучены\n",
        "- [x]  Значение метрики *F1* не меньше 0.75\n",
        "- [x]  Выводы написаны"
      ]
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 450,
        "start_time": "2023-06-27T12:05:08.832Z"
      },
      {
        "duration": 4278,
        "start_time": "2023-06-27T12:05:52.040Z"
      },
      {
        "duration": 24,
        "start_time": "2023-06-27T12:05:56.735Z"
      },
      {
        "duration": 1005,
        "start_time": "2023-06-27T12:06:50.131Z"
      },
      {
        "duration": 12,
        "start_time": "2023-06-27T12:06:52.283Z"
      },
      {
        "duration": 48,
        "start_time": "2023-06-27T12:07:08.332Z"
      },
      {
        "duration": 133,
        "start_time": "2023-06-27T12:09:44.314Z"
      },
      {
        "duration": 6,
        "start_time": "2023-06-27T12:11:11.130Z"
      },
      {
        "duration": 2353,
        "start_time": "2023-06-27T12:12:06.447Z"
      },
      {
        "duration": 112,
        "start_time": "2023-06-27T12:12:29.048Z"
      },
      {
        "duration": 2781,
        "start_time": "2023-06-27T12:12:37.021Z"
      },
      {
        "duration": 156,
        "start_time": "2023-06-27T12:18:31.131Z"
      },
      {
        "duration": 1401,
        "start_time": "2023-06-27T12:18:42.522Z"
      },
      {
        "duration": 5975,
        "start_time": "2023-06-27T12:18:43.925Z"
      },
      {
        "duration": 35,
        "start_time": "2023-06-27T12:18:49.909Z"
      },
      {
        "duration": 61,
        "start_time": "2023-06-27T12:18:49.951Z"
      },
      {
        "duration": 30,
        "start_time": "2023-06-27T12:18:50.024Z"
      },
      {
        "duration": 2523,
        "start_time": "2023-06-27T12:18:50.066Z"
      },
      {
        "duration": 1636,
        "start_time": "2023-06-27T12:19:22.319Z"
      },
      {
        "duration": 972,
        "start_time": "2023-06-27T12:19:53.525Z"
      },
      {
        "duration": 16106,
        "start_time": "2023-06-27T12:28:44.680Z"
      },
      {
        "duration": 3060,
        "start_time": "2023-06-27T12:29:47.908Z"
      },
      {
        "duration": 14,
        "start_time": "2023-06-27T12:30:04.682Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-27T12:30:16.112Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-27T12:30:28.829Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-27T12:30:51.612Z"
      },
      {
        "duration": 3,
        "start_time": "2023-06-27T12:31:25.421Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-27T12:35:17.044Z"
      },
      {
        "duration": 4361,
        "start_time": "2023-06-27T12:36:12.733Z"
      },
      {
        "duration": 3435,
        "start_time": "2023-06-27T12:36:17.097Z"
      },
      {
        "duration": 15,
        "start_time": "2023-06-27T12:36:20.534Z"
      },
      {
        "duration": 93,
        "start_time": "2023-06-27T12:36:20.550Z"
      },
      {
        "duration": 2145,
        "start_time": "2023-06-27T12:36:20.646Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-27T12:39:14.380Z"
      },
      {
        "duration": 208,
        "start_time": "2023-06-27T12:39:18.622Z"
      },
      {
        "duration": 3,
        "start_time": "2023-06-27T12:39:44.607Z"
      },
      {
        "duration": 1511,
        "start_time": "2023-06-27T12:39:46.183Z"
      },
      {
        "duration": 8,
        "start_time": "2023-06-27T12:40:00.280Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-27T12:45:21.776Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-27T12:45:24.539Z"
      },
      {
        "duration": 13,
        "start_time": "2023-06-27T12:46:06.145Z"
      },
      {
        "duration": 5,
        "start_time": "2023-06-27T12:46:29.233Z"
      },
      {
        "duration": 82,
        "start_time": "2023-06-27T12:51:52.238Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-27T12:53:50.313Z"
      },
      {
        "duration": 6,
        "start_time": "2023-06-27T12:54:15.493Z"
      },
      {
        "duration": 5,
        "start_time": "2023-06-27T12:55:15.305Z"
      },
      {
        "duration": 5,
        "start_time": "2023-06-27T12:55:40.919Z"
      },
      {
        "duration": 3,
        "start_time": "2023-06-27T12:57:47.232Z"
      },
      {
        "duration": 7,
        "start_time": "2023-06-27T12:57:51.643Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-27T12:58:34.836Z"
      },
      {
        "duration": 24,
        "start_time": "2023-06-27T12:58:35.978Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-27T12:58:42.624Z"
      },
      {
        "duration": 5,
        "start_time": "2023-06-27T12:58:43.505Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-27T12:59:53.305Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-27T13:00:07.626Z"
      },
      {
        "duration": 3,
        "start_time": "2023-06-27T13:00:29.609Z"
      },
      {
        "duration": 9,
        "start_time": "2023-06-27T13:00:30.308Z"
      },
      {
        "duration": 13,
        "start_time": "2023-06-27T13:00:42.070Z"
      },
      {
        "duration": 3,
        "start_time": "2023-06-27T13:00:49.524Z"
      },
      {
        "duration": 12,
        "start_time": "2023-06-27T13:05:13.422Z"
      },
      {
        "duration": 22,
        "start_time": "2023-06-27T13:05:30.707Z"
      },
      {
        "duration": 19,
        "start_time": "2023-06-27T13:06:04.312Z"
      },
      {
        "duration": 20,
        "start_time": "2023-06-27T13:06:19.711Z"
      },
      {
        "duration": 22,
        "start_time": "2023-06-27T13:06:48.813Z"
      },
      {
        "duration": 9,
        "start_time": "2023-06-27T13:06:59.220Z"
      },
      {
        "duration": 49,
        "start_time": "2023-06-27T13:11:04.212Z"
      },
      {
        "duration": 27866,
        "start_time": "2023-06-27T13:13:08.914Z"
      },
      {
        "duration": 28571,
        "start_time": "2023-06-27T13:18:49.121Z"
      },
      {
        "duration": 5,
        "start_time": "2023-06-27T13:21:42.140Z"
      },
      {
        "duration": 8,
        "start_time": "2023-06-27T13:22:18.310Z"
      },
      {
        "duration": 1981,
        "start_time": "2023-06-28T07:19:36.434Z"
      },
      {
        "duration": 3674,
        "start_time": "2023-06-28T07:19:38.417Z"
      },
      {
        "duration": 13,
        "start_time": "2023-06-28T07:19:42.093Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-28T07:19:42.108Z"
      },
      {
        "duration": 35,
        "start_time": "2023-06-28T07:19:42.120Z"
      },
      {
        "duration": 2097,
        "start_time": "2023-06-28T07:19:42.156Z"
      },
      {
        "duration": 6,
        "start_time": "2023-06-28T07:19:44.255Z"
      },
      {
        "duration": 1207,
        "start_time": "2023-06-28T07:19:44.263Z"
      },
      {
        "duration": 3,
        "start_time": "2023-06-28T07:19:45.472Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-28T07:19:45.477Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-28T07:19:45.489Z"
      },
      {
        "duration": 1073489,
        "start_time": "2023-06-28T07:19:45.513Z"
      },
      {
        "duration": 7,
        "start_time": "2023-06-28T07:37:39.179Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-28T08:14:15.267Z"
      },
      {
        "duration": 5,
        "start_time": "2023-06-28T08:14:40.951Z"
      },
      {
        "duration": 227,
        "start_time": "2023-06-28T08:17:16.679Z"
      },
      {
        "duration": 6,
        "start_time": "2023-06-28T08:18:24.666Z"
      },
      {
        "duration": 119,
        "start_time": "2023-06-28T08:18:47.708Z"
      },
      {
        "duration": 137,
        "start_time": "2023-06-28T08:20:51.846Z"
      },
      {
        "duration": 170,
        "start_time": "2023-06-28T08:21:08.533Z"
      },
      {
        "duration": 153,
        "start_time": "2023-06-28T08:21:31.913Z"
      },
      {
        "duration": 179,
        "start_time": "2023-06-28T08:21:56.909Z"
      },
      {
        "duration": 164,
        "start_time": "2023-06-28T08:22:10.234Z"
      },
      {
        "duration": 139,
        "start_time": "2023-06-28T08:22:25.236Z"
      },
      {
        "duration": 250,
        "start_time": "2023-06-28T08:22:32.682Z"
      },
      {
        "duration": 116,
        "start_time": "2023-06-28T08:22:56.643Z"
      },
      {
        "duration": 342,
        "start_time": "2023-06-28T08:41:25.067Z"
      },
      {
        "duration": 19,
        "start_time": "2023-06-28T08:43:48.762Z"
      },
      {
        "duration": 4708,
        "start_time": "2023-06-28T08:57:31.210Z"
      },
      {
        "duration": 3910,
        "start_time": "2023-06-28T08:57:35.920Z"
      },
      {
        "duration": 26,
        "start_time": "2023-06-28T08:57:39.833Z"
      },
      {
        "duration": 18,
        "start_time": "2023-06-28T08:57:39.861Z"
      },
      {
        "duration": 52,
        "start_time": "2023-06-28T08:57:39.884Z"
      },
      {
        "duration": 6,
        "start_time": "2023-06-28T08:57:39.939Z"
      },
      {
        "duration": 199,
        "start_time": "2023-06-28T08:57:39.948Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-28T08:57:40.151Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-28T08:57:40.152Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-28T08:57:40.153Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-28T08:57:40.156Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-28T08:57:40.158Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-28T08:57:40.159Z"
      },
      {
        "duration": 1,
        "start_time": "2023-06-28T08:57:40.160Z"
      },
      {
        "duration": 5,
        "start_time": "2023-06-28T09:03:11.325Z"
      },
      {
        "duration": 892,
        "start_time": "2023-06-28T09:03:11.332Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-28T09:03:12.226Z"
      },
      {
        "duration": 39,
        "start_time": "2023-06-28T09:03:12.238Z"
      },
      {
        "duration": 63,
        "start_time": "2023-06-28T09:03:12.280Z"
      },
      {
        "duration": 163,
        "start_time": "2023-06-28T09:03:12.346Z"
      },
      {
        "duration": 34,
        "start_time": "2023-06-28T09:03:12.511Z"
      },
      {
        "duration": 1649058,
        "start_time": "2023-06-28T09:03:12.547Z"
      },
      {
        "duration": 29,
        "start_time": "2023-06-28T09:30:41.613Z"
      },
      {
        "duration": 14,
        "start_time": "2023-06-28T09:30:41.644Z"
      },
      {
        "duration": 127,
        "start_time": "2023-06-28T09:30:41.661Z"
      },
      {
        "duration": 312,
        "start_time": "2023-06-28T09:30:41.790Z"
      },
      {
        "duration": 1990,
        "start_time": "2023-06-28T09:30:42.104Z"
      },
      {
        "duration": 17,
        "start_time": "2023-06-28T09:30:44.098Z"
      },
      {
        "duration": 27,
        "start_time": "2023-06-28T09:30:44.117Z"
      },
      {
        "duration": 62,
        "start_time": "2023-06-28T09:31:42.963Z"
      },
      {
        "duration": 2349,
        "start_time": "2023-06-28T09:39:07.145Z"
      },
      {
        "duration": 3844,
        "start_time": "2023-06-28T09:39:09.496Z"
      },
      {
        "duration": 20,
        "start_time": "2023-06-28T09:39:13.342Z"
      },
      {
        "duration": 32,
        "start_time": "2023-06-28T09:39:13.364Z"
      },
      {
        "duration": 36,
        "start_time": "2023-06-28T09:39:13.399Z"
      },
      {
        "duration": 5,
        "start_time": "2023-06-28T09:39:13.437Z"
      },
      {
        "duration": 36,
        "start_time": "2023-06-28T09:39:13.444Z"
      },
      {
        "duration": 1366229,
        "start_time": "2023-06-28T09:39:13.483Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-28T10:04:35.940Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-28T10:04:37.361Z"
      },
      {
        "duration": 109,
        "start_time": "2023-06-28T10:04:39.387Z"
      },
      {
        "duration": 301,
        "start_time": "2023-06-28T10:04:42.239Z"
      },
      {
        "duration": 2517,
        "start_time": "2023-06-28T10:04:43.450Z"
      },
      {
        "duration": 9800,
        "start_time": "2023-06-28T10:04:45.970Z"
      },
      {
        "duration": 9960,
        "start_time": "2023-06-28T10:04:55.773Z"
      },
      {
        "duration": 241,
        "start_time": "2023-06-28T10:05:05.735Z"
      },
      {
        "duration": 14071,
        "start_time": "2023-06-28T10:05:24.039Z"
      },
      {
        "duration": 14593,
        "start_time": "2023-06-28T10:05:54.072Z"
      },
      {
        "duration": 10355,
        "start_time": "2023-06-28T10:07:16.821Z"
      },
      {
        "duration": 10924,
        "start_time": "2023-06-28T10:07:27.178Z"
      },
      {
        "duration": 1203,
        "start_time": "2023-06-28T13:30:54.834Z"
      },
      {
        "duration": 3036,
        "start_time": "2023-06-28T13:30:56.039Z"
      },
      {
        "duration": 13,
        "start_time": "2023-06-28T13:30:59.077Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-28T13:30:59.092Z"
      },
      {
        "duration": 28,
        "start_time": "2023-06-28T13:30:59.107Z"
      },
      {
        "duration": 12,
        "start_time": "2023-06-28T13:30:59.136Z"
      },
      {
        "duration": 5,
        "start_time": "2023-06-28T13:30:59.150Z"
      },
      {
        "duration": 723826,
        "start_time": "2023-06-28T13:30:59.156Z"
      },
      {
        "duration": 7,
        "start_time": "2023-06-28T13:43:02.983Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-28T13:43:02.991Z"
      },
      {
        "duration": 64,
        "start_time": "2023-06-28T13:43:03.003Z"
      },
      {
        "duration": 226,
        "start_time": "2023-06-28T13:43:03.068Z"
      },
      {
        "duration": 3,
        "start_time": "2023-06-28T13:43:03.295Z"
      },
      {
        "duration": 5416,
        "start_time": "2023-06-28T13:43:03.300Z"
      },
      {
        "duration": 5665,
        "start_time": "2023-06-28T13:43:08.717Z"
      },
      {
        "duration": 5484,
        "start_time": "2023-06-28T13:43:14.384Z"
      },
      {
        "duration": 6201,
        "start_time": "2023-06-28T13:43:19.869Z"
      },
      {
        "duration": 29339,
        "start_time": "2023-06-28T13:43:26.072Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-28T13:43:55.412Z"
      },
      {
        "duration": 30,
        "start_time": "2023-06-28T13:43:55.417Z"
      },
      {
        "duration": 929427,
        "start_time": "2023-06-28T13:43:55.448Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-28T13:59:24.877Z"
      },
      {
        "duration": 340061,
        "start_time": "2023-06-28T13:59:24.882Z"
      },
      {
        "duration": 6,
        "start_time": "2023-06-28T14:05:04.944Z"
      },
      {
        "duration": 1578,
        "start_time": "2023-06-28T14:05:04.952Z"
      },
      {
        "duration": 7,
        "start_time": "2023-06-28T14:05:06.531Z"
      },
      {
        "duration": 1415,
        "start_time": "2023-06-30T12:34:52.550Z"
      },
      {
        "duration": 2267,
        "start_time": "2023-06-30T12:34:53.967Z"
      },
      {
        "duration": 13,
        "start_time": "2023-06-30T12:34:56.237Z"
      },
      {
        "duration": 17,
        "start_time": "2023-06-30T12:34:56.252Z"
      },
      {
        "duration": 33,
        "start_time": "2023-06-30T12:34:56.271Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-30T12:34:56.306Z"
      },
      {
        "duration": 8,
        "start_time": "2023-06-30T12:34:56.312Z"
      },
      {
        "duration": 9,
        "start_time": "2023-06-30T12:34:56.322Z"
      },
      {
        "duration": 1359,
        "start_time": "2023-06-30T12:34:56.333Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.694Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.695Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.697Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.698Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.699Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.700Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.701Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.702Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.703Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.703Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.704Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.705Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.706Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.707Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.708Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.709Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.710Z"
      },
      {
        "duration": 0,
        "start_time": "2023-06-30T12:34:57.711Z"
      },
      {
        "duration": 646,
        "start_time": "2023-06-30T12:36:10.962Z"
      },
      {
        "duration": 118,
        "start_time": "2023-06-30T12:36:16.699Z"
      },
      {
        "duration": 1453,
        "start_time": "2023-06-30T12:37:30.388Z"
      },
      {
        "duration": 900,
        "start_time": "2023-06-30T12:37:31.844Z"
      },
      {
        "duration": 20,
        "start_time": "2023-06-30T12:37:32.747Z"
      },
      {
        "duration": 31,
        "start_time": "2023-06-30T12:37:32.769Z"
      },
      {
        "duration": 85,
        "start_time": "2023-06-30T12:37:32.803Z"
      },
      {
        "duration": 23,
        "start_time": "2023-06-30T12:37:32.890Z"
      },
      {
        "duration": 27,
        "start_time": "2023-06-30T12:37:32.915Z"
      },
      {
        "duration": 40,
        "start_time": "2023-06-30T12:37:32.944Z"
      },
      {
        "duration": 252,
        "start_time": "2023-06-30T12:37:32.986Z"
      },
      {
        "duration": 2318486,
        "start_time": "2023-06-30T12:37:33.240Z"
      },
      {
        "duration": 8,
        "start_time": "2023-06-30T13:16:11.728Z"
      },
      {
        "duration": 49,
        "start_time": "2023-06-30T13:16:11.738Z"
      },
      {
        "duration": 114,
        "start_time": "2023-06-30T13:16:11.789Z"
      },
      {
        "duration": 5,
        "start_time": "2023-06-30T13:16:11.907Z"
      },
      {
        "duration": 88,
        "start_time": "2023-06-30T13:16:11.914Z"
      },
      {
        "duration": 6753,
        "start_time": "2023-06-30T13:16:12.004Z"
      },
      {
        "duration": 7504,
        "start_time": "2023-06-30T13:16:18.766Z"
      },
      {
        "duration": 6786,
        "start_time": "2023-06-30T13:16:26.278Z"
      },
      {
        "duration": 7376,
        "start_time": "2023-06-30T13:16:33.065Z"
      },
      {
        "duration": 31577,
        "start_time": "2023-06-30T13:16:40.443Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-30T13:17:12.021Z"
      },
      {
        "duration": 64,
        "start_time": "2023-06-30T13:17:12.027Z"
      },
      {
        "duration": 1298167,
        "start_time": "2023-06-30T13:17:12.092Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-30T13:38:50.261Z"
      },
      {
        "duration": 432961,
        "start_time": "2023-06-30T13:38:50.267Z"
      },
      {
        "duration": 7,
        "start_time": "2023-06-30T13:46:03.229Z"
      },
      {
        "duration": 2229,
        "start_time": "2023-06-30T13:46:03.237Z"
      },
      {
        "duration": 13,
        "start_time": "2023-06-30T13:46:05.467Z"
      }
    ],
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Содержание",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "302.391px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}